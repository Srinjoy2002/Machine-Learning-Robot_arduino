{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrVI6ct3ByBGbEV5Zjj1IQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srinjoy2002/Machine-Learning-Robot_arduino/blob/main/SIHv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N20bzZQs8uto",
        "outputId": "007be30e-55b0-47c0-cae5-26127f3d6358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.44)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"UnoiVQqm728ScpgMtjQd\")\n",
        "project = rf.workspace(\"personal-yatgp\").project(\"sih-mhvih\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"voc\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4Me2wjoBK7G",
        "outputId": "6fe41c82-6a97-4e1e-c2b7-e74fc9705b02"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install Required Libraries\n",
        "!pip install roboflow\n",
        "!pip install tensorflow\n",
        "\n",
        "# Step 2: Import Libraries\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# Step 3: Download Dataset from Roboflow\n",
        "rf = Roboflow(api_key=\"UnoiVQqm728ScpgMtjQd\")\n",
        "project = rf.workspace(\"personal-yatgp\").project(\"sih-mhvih\")\n",
        "version = project.version(2)\n",
        "\n",
        "# Download dataset in Pascal VOC format\n",
        "dataset = version.download(\"voc\")\n",
        "\n",
        "# Set up the dataset directories\n",
        "train_dir = dataset.location + '/train'\n",
        "val_dir = dataset.location + '/valid'\n",
        "test_dir = dataset.location + '/test'\n",
        "\n",
        "print(f\"Train directory: {train_dir}\")\n",
        "print(f\"Validation directory: {val_dir}\")\n",
        "print(f\"Test directory: {test_dir}\")\n",
        "\n",
        "# Step 4: Define Label Map (For Three Classes)\n",
        "label_map = {\n",
        "    'FoundationDone': 0,\n",
        "    'Beams': 1,\n",
        "    'Neither': 2  # Added Neither class for images with neither Foundation nor Beams\n",
        "}\n",
        "\n",
        "# Step 5: Parse Pascal VOC Annotations (Images and Annotations in Same Directory), skipping unknown labels\n",
        "def parse_voc_annotation_same_dir(annotation_dir, label_map):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for file in os.listdir(annotation_dir):\n",
        "        if file.endswith('.xml'):  # Look for XML files\n",
        "            tree = ET.parse(os.path.join(annotation_dir, file))\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Get the image filename from the XML and construct its full path\n",
        "            img_file = root.find('filename').text\n",
        "            img_path = os.path.join(annotation_dir, img_file)\n",
        "\n",
        "            # Get label from <object><name> tag in the XML\n",
        "            label = root.find('object').find('name').text\n",
        "\n",
        "            if label in label_map:  # Only append if label is in label_map\n",
        "                images.append(img_path)\n",
        "                labels.append(label_map[label])  # Convert class name to index\n",
        "            else:\n",
        "                print(f\"Skipping file {img_file} with unknown label: {label}\")\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Parse train, validation, and test sets, skipping unknown labels\n",
        "train_images, train_labels = parse_voc_annotation_same_dir(train_dir, label_map)\n",
        "val_images, val_labels = parse_voc_annotation_same_dir(val_dir, label_map)\n",
        "test_images, test_labels = parse_voc_annotation_same_dir(test_dir, label_map)\n",
        "\n",
        "print(f\"Train dataset: {len(train_images)} images\")\n",
        "print(f\"Validation dataset: {len(val_images)} images\")\n",
        "print(f\"Test dataset: {len(test_images)} images\")\n",
        "\n",
        "# Step 6: Data Loading and Preprocessing\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def load_and_preprocess_image(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0  # Normalize to [0,1] range\n",
        "    return img, label\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.map(load_and_preprocess_image).batch(BATCH_SIZE).shuffle(buffer_size=len(train_images))\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_ds = val_ds.map(load_and_preprocess_image).batch(BATCH_SIZE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.map(load_and_preprocess_image).batch(BATCH_SIZE)\n",
        "\n",
        "# Step 7: Define ResNet50 Model for Multi-class Classification\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom layers on top for multi-class classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)  # Three units with softmax for multi-class classification\n",
        "\n",
        "# Define the full model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base ResNet50 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model for multi-class classification\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 8: Train the Model with Time, Accuracy, and Loss Tracking\n",
        "class TimingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.times.append(time.time() - self.start_time)\n",
        "        self.logs.append(logs)\n",
        "        print(f\"Epoch {epoch+1}: Time taken: {self.times[-1]:.2f}s, Accuracy: {logs['accuracy']:.4f}, Loss: {logs['loss']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}, Validation Loss: {logs['val_loss']:.4f}\")\n",
        "\n",
        "# Initialize the timing callback\n",
        "timing_callback = TimingCallback()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGzVObKC89JO",
        "outputId": "5c4383f4-b264-48ba-babc-fabcd4cb18af"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.44)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.53.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Train directory: /content/SIH-2/train\n",
            "Validation directory: /content/SIH-2/valid\n",
            "Test directory: /content/SIH-2/test\n",
            "Skipping file pexels-roger-brown-3435524-5125782_jpg.rf.1bbec1f1199c7c869c7b9a129a949b8c.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_21_png.rf.5a4709f3064951cd12ba27a812d40129.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_1_jpeg.rf.5f659990b33349e26aec8c640c84804e.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_25_jpeg.rf.be77dd0354f58a11f0bb1ed1217cc530.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_72_jpeg.rf.f7f69a1985371b7c726cecdbdc94bade.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_14_jpeg.rf.dbcb05bea8a8a16c87331bbb8db22674.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file pexels-printexstar-11680715_jpg.rf.6d63d91be2e377b17dfd4817c3952a9f.jpg with unknown label: grndclr\n",
            "Skipping file Screenshot-2024-08-28-162401_png.rf.20b3bad853108d259d5826a17597158d.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_34_jpeg.rf.d4aa6802f94a69bc8cd87aceeefd0be6.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_1_jpeg.rf.d050d99fe9651dca292996c79c514384.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_14_jpeg.rf.9ec184ab74861cf09acbf26de11da3a7.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_47_jpeg.rf.1454834c871a8077df773f27557a2c6a.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_47_jpeg.rf.831bbec52a2e179cc29d792a87c5f524.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_6_jpeg.rf.d75f4a1c060783bd5aa5010d469e47ac.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file pexels-roger-brown-3435524-5125782_jpg.rf.819105f06f55602cb78d3eb3682f7cb1.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_25_jpeg.rf.f04d6e72fe5b5b75cb97b1b3d38746e3.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_34_jpeg.rf.aa6c1968dda7096a6e678eba0856cf4f.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_21_png.rf.92de9111a831a2bb7867d76ccd19f9f3.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file pexels-roger-brown-3435524-5125782_jpg.rf.e69c1eac6b596de13c6c3abec09b6726.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_19_jpeg.rf.77c1e07bbde85bd1077e0cef7b78c5bc.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Screenshot-2024-08-28-162401_png.rf.2502a5be0c73029ed662b92f941e2285.jpg with unknown label: grndclr\n",
            "Skipping file pexels-printexstar-11680715_jpg.rf.4afaaac70a64633fb6ec1e3fc9b0d13d.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_6_jpeg.rf.d9bb5c114990ae3f686874fb336b17d2.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_34_jpeg.rf.88585fe778581d2129187ed2fc5fc53a.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_25_jpeg.rf.be23aa2d4ad032344a87eeaab7ac8666.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_19_jpeg.rf.46cbc8fb8ce9531e2a616a1ab882cd4d.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_6_jpeg.rf.971d28a72ed0c39397af9d2d55ed1d37.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file pexels-printexstar-11680715_jpg.rf.96e8b03972e6d181487b6e2b77ad91c2.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_14_jpeg.rf.c0348a201da0ec40be1f4e1f718fffd4.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_47_jpeg.rf.f00fda9b2f7fafc5859dee44199946fc.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_19_jpeg.rf.1ad15335220f5ec06c6408e758881046.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Screenshot-2024-08-28-162401_png.rf.e509e43f7b2d7be48e04eca75f492eab.jpg with unknown label: grndclr\n",
            "Skipping file Bridge-foundation_72_jpeg.rf.74ce144049020ddb87f992ddc9043d05.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_72_jpeg.rf.3e95d3a31131e2a9bfcb016727e8e2cf.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_21_png.rf.57248587d54732f0078903e4bf0711a2.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_1_jpeg.rf.f6edc86f9b20f50b57c2f8f6cbbd65a2.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_26_jpeg.rf.3f3e03cb516407942b27eae07e35817b.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_58_jpeg.rf.25a135526715f9dbea70fac73f0443e3.jpg with unknown label: BridgeStrucDone\n",
            "Skipping file Bridge-foundation_2_jpeg.rf.18858f9b030b1e323c7d2830379f2190.jpg with unknown label: BridgeStrucDone\n",
            "Train dataset: 249 images\n",
            "Validation dataset: 10 images\n",
            "Test dataset: 13 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=100,  # Adjust based on dataset size and performance\n",
        "    callbacks=[timing_callback]\n",
        ")\n",
        "\n",
        "# Step 9: Evaluate the Model on the Test Set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Step 10: Save the Model\n",
        "model.save('construction_progress_resnet_model.h5')\n",
        "\n",
        "# Step 11: Make Predictions on New Images\n",
        "def predict_image(img_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0  # Normalize to [0,1]\n",
        "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    # Map prediction index to class name\n",
        "    class_labels = ['FoundationDone', 'Beams', 'Neither']\n",
        "    predicted_class = class_labels[tf.argmax(prediction[0])]\n",
        "    return predicted_class\n",
        "\n",
        "# # Example: Test on a new image\n",
        "# new_image_path = 'path_to_new_image.jpg'  # Update with the path to your image\n",
        "# predicted_class = predict_image(new_image_path)\n",
        "# print(f'The predicted class is: {predicted_class}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzYq4-Dv-ULs",
        "outputId": "3b1ce8fc-755d-4c02-f521-3287071102e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768ms/step - accuracy: 0.5810 - loss: 0.9964Epoch 1: Time taken: 27.78s, Accuracy: 0.6426, Loss: 0.9005, Validation Accuracy: 0.1000, Validation Loss: 0.9407\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2s/step - accuracy: 0.5878 - loss: 0.9858 - val_accuracy: 0.1000 - val_loss: 0.9407\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6294 - loss: 0.6986Epoch 2: Time taken: 1.25s, Accuracy: 0.7590, Loss: 0.6202, Validation Accuracy: 0.9000, Validation Loss: 0.3112\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.6438 - loss: 0.6899 - val_accuracy: 0.9000 - val_loss: 0.3112\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7780 - loss: 0.6532Epoch 3: Time taken: 1.28s, Accuracy: 0.8233, Loss: 0.5517, Validation Accuracy: 0.9000, Validation Loss: 0.3404\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.7830 - loss: 0.6419 - val_accuracy: 0.9000 - val_loss: 0.3404\n",
            "Epoch 4/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install tensorflow roboflow\n"
      ],
      "metadata": {
        "id": "zZZ6lJW5CEMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from roboflow import Roboflow\n"
      ],
      "metadata": {
        "id": "AYUWX-6hCE7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image size and batch size\n",
        "IMG_SIZE = (224, 224)  # Adjust size as needed\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Define label map\n",
        "label_map = {'FoundationDone': 0, 'Beams': 1, 'Neither': 2}\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_and_preprocess_image(img_path, label):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0  # Normalize to [0,1]\n",
        "    return img, label\n",
        "\n",
        "# Parse VOC annotations and prepare datasets\n",
        "def parse_voc_annotation_same_dir(annotation_dir, label_map):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for file in os.listdir(annotation_dir):\n",
        "        if file.endswith('.xml'):  # Check for XML annotation files\n",
        "            tree = ET.parse(os.path.join(annotation_dir, file))\n",
        "            root = tree.getroot()\n",
        "\n",
        "            # Get image filename from the XML and construct the full path\n",
        "            image_file = root.find('path').text\n",
        "            image_path = os.path.join(annotation_dir, image_file)\n",
        "\n",
        "            # Get label from <object><name> tag in the XML\n",
        "            objects = root.findall('object')\n",
        "            has_label = False\n",
        "            for obj in objects:\n",
        "                label = obj.find('name').text\n",
        "                if label in label_map:\n",
        "                    images.append(image_path)\n",
        "                    labels.append(label_map[label])\n",
        "                    has_label = True\n",
        "                    break  # Skip to next image if any valid label is found\n",
        "            if not has_label:\n",
        "                images.append(image_path)\n",
        "                labels.append(label_map['Neither'])  # No valid label found, assign 'Neither'\n",
        "    return images, labels\n",
        "\n",
        "# Define paths to dataset directories\n",
        "train_dir = '/content/SIH-2/train'\n",
        "val_dir = '/content/SIH-2/valid'\n",
        "test_dir = '/content/SIH-2/test'\n",
        "\n",
        "# Parse train, validation, and test sets\n",
        "train_images, train_labels = parse_voc_annotation_same_dir(train_dir, label_map)\n",
        "val_images, val_labels = parse_voc_annotation_same_dir(val_dir, label_map)\n",
        "test_images, test_labels = parse_voc_annotation_same_dir(test_dir, label_map)\n"
      ],
      "metadata": {
        "id": "WCFvpfOZCHwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow datasets with optimization\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "train_ds = train_ds.batch(BATCH_SIZE).shuffle(buffer_size=len(train_images))\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
        "val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_ds = test_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "TFcevXwTCMAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet model\n",
        "def create_resnet_model(num_classes):\n",
        "    base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base_model.output\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "    x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "num_classes = len(label_map)\n",
        "model = create_resnet_model(num_classes)\n"
      ],
      "metadata": {
        "id": "iEoXrRg_CP_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Timing callback to track epoch time\n",
        "class TimingCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.times = []\n",
        "        self.logs = []\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.times.append(time.time() - self.start_time)\n",
        "        self.logs.append(logs)\n",
        "        print(f\"Epoch {epoch+1}: Time taken: {self.times[-1]:.2f}s, Accuracy: {logs['accuracy']:.4f}, Loss: {logs['loss']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}, Validation Loss: {logs['val_loss']:.4f}\")\n",
        "\n",
        "# Initialize the timing callback\n",
        "timing_callback = TimingCallback()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=100,  # Adjust based on dataset size and performance\n",
        "    callbacks=[timing_callback]\n",
        ")\n"
      ],
      "metadata": {
        "id": "6QjoFYQJCTbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "cuihddMdCaHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('construction_progress_resnet_model.h5')\n",
        "# Function to make predictions on new images\n",
        "def get_status_message(predicted_class):\n",
        "    \"\"\"Returns a status message based on the predicted class.\"\"\"\n",
        "    messages = {\n",
        "        'FoundationDone': 'The foundation is completed. Next, walls and beams need to be constructed.',\n",
        "        'Beams': 'The ground is dug, and beams are erected. Now, the concrete should be poured.',\n",
        "        'Neither': 'No construction progress is detected. Please check the construction status.'\n",
        "    }\n",
        "    return messages.get(predicted_class, 'Unknown status')\n",
        "\n",
        "def predict_image(img_path):\n",
        "    \"\"\"Predicts the class of the image and provides a status message.\"\"\"\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0  # Normalize to [0,1]\n",
        "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    # Map prediction index to class name\n",
        "    class_labels = ['FoundationDone', 'Beams', 'Neither']\n",
        "    predicted_class = class_labels[tf.argmax(prediction[0])]\n",
        "\n",
        "    # Get the status message based on the predicted class\n",
        "    status_message = get_status_message(predicted_class)\n",
        "\n",
        "    return predicted_class, status_message\n",
        "\n",
        "# Example: Test on a new image\n",
        "new_image_path = '/content/00fc01e0-3acb-4abd-bc76-3a4d2e4ae074.jpeg'  # Update with the path to your image\n",
        "predicted_class, status_message = predict_image(new_image_path)\n",
        "print(f'The predicted class is: {predicted_class}')\n",
        "print(f'Status message: {status_message}')\n",
        "\n"
      ],
      "metadata": {
        "id": "se19Zg30CdIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_classes):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze the base model layers\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_model(num_classes=3)  # Number of classes including 'Neither'\n"
      ],
      "metadata": {
        "id": "yGDruSiNFMqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True)\n",
        "\n",
        "# Train the model with callbacks\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=100,  # Adjust based on dataset size and performance\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluate the Model on the Test Set\n",
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the Model\n",
        "model.save('final_construction_progress_resnet_model.keras')\n",
        "\n",
        "# Make Predictions on New Images\n",
        "def predict_image(img_path):\n",
        "    \"\"\"Predicts the class of the image and provides a status message.\"\"\"\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    img = img / 255.0  # Normalize to [0,1]\n",
        "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "\n",
        "    # Map prediction index to class name\n",
        "    class_labels = ['FoundationDone', 'Beams', 'Neither']\n",
        "    predicted_class = class_labels[tf.argmax(prediction[0])]\n",
        "\n",
        "    # Get the status message based on the predicted class\n",
        "    status_message = get_status_message(predicted_class)\n",
        "\n",
        "    return predicted_class, status_message\n",
        "\n",
        "# Example: Test on a new image\n",
        "new_image_path = '/content/00fc01e0-3acb-4abd-bc76-3a4d2e4ae074.jpeg'  # Update with the path to your image\n",
        "predicted_class, status_message = predict_image(new_image_path)\n",
        "print(f'The predicted class is: {predicted_class}')\n",
        "print(f'Status message: {status_message}')\n"
      ],
      "metadata": {
        "id": "QSpGGe-cFmw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3lHJy3eFpWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}